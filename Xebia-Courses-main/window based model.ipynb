{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#window based model\n",
        "#glove-window based model (context usage)\n",
        "#after glove we have : word->vector, but nlp tasks wont be for one single word.\n",
        "#they are about word-> surroundin words...\n",
        "#so we need to use a window\n",
        "\n",
        "#window=is fixed  number of words arround a target word\n"
      ],
      "metadata": {
        "id": "TnpVkc9yCLuh"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#predict the intent using a sliding window over sentence embeddings\n",
        "#this will show us how embeddings are embedded as features."
      ],
      "metadata": {
        "id": "FH9zJWEHGj0N"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "id": "1KrG68wLHPw2",
        "outputId": "992b8be9-9d70-4d9a-ace8-b106937f943a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.1.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim.downloader as api\n",
        "import numpy as np\n",
        "from nltk.tokenize import word_tokenize"
      ],
      "metadata": {
        "id": "u6zLKM6RGwwF"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"loading model...\");\n",
        "model=api.load(\"glove-wiki-gigaword-100\")\n",
        "print(\"model loaded\")"
      ],
      "metadata": {
        "id": "BXFww1r4G-FJ",
        "outputId": "899e51c0-2121-461e-ac5b-39d7890a9330",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "loading model...\n",
            "[==================================================] 100.0% 128.1/128.1MB downloaded\n",
            "model loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n"
      ],
      "metadata": {
        "id": "6bJa2Q5DH5W9",
        "outputId": "1e1e96c6-5ccc-4f63-db8b-3cebb876ce4e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "nltk.download('averaged_perceptron_tagger')"
      ],
      "metadata": {
        "id": "WI1nVHD2ICIJ",
        "outputId": "a069c266-98e5-4d13-edad-1d5b5068db43",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence=\"please open google and check weather\"\n",
        "tokens=word_tokenize(sentence.lower())\n"
      ],
      "metadata": {
        "id": "Ju1mgbLjHUnY"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#sliding window fn\n",
        "def get_windows(tokens,window_size=2):\n",
        "  windows=[]\n",
        "  for i in range(len(tokens)):#0\n",
        "    left=max(0,i-window_size)#(0,-2)=0\n",
        "    right=min(len(tokens),i+window_size+1)#(6,3)=3\n",
        "    window_words=tokens[left:right]#[0:3]\n",
        "    windows.append(window_words)#(0,1,2)......continued\n",
        "  return windows"
      ],
      "metadata": {
        "id": "FgujjxF8IE0c"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windows=get_windows(tokens,2)\n",
        "print(\"windows:\\n\",windows)"
      ],
      "metadata": {
        "id": "PgbCpFvlIfnH",
        "outputId": "e6e605c5-b94a-4f8e-fc6c-39eeb93caa66",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "windows:\n",
            " [['please', 'open', 'google'], ['please', 'open', 'google', 'and'], ['please', 'open', 'google', 'and', 'check'], ['open', 'google', 'and', 'check', 'weather'], ['google', 'and', 'check', 'weather'], ['and', 'check', 'weather']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def window_vector(window):\n",
        "  vectors=[]\n",
        "  for word in window:\n",
        "    if word in model:\n",
        "      vectors.append(model[word])\n",
        "  if len(vectors)==0:\n",
        "      return np.zeros(100)\n",
        "\n",
        "  return np.mean(vectors,axis=0)"
      ],
      "metadata": {
        "id": "grPDoEHNKIkR"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "window_vectors=[window_vector(w) for w in windows]\n",
        "print(window_vectors[0].shape)"
      ],
      "metadata": {
        "id": "xNsrAwxGKnU1",
        "outputId": "a29e8c69-f06e-4284-b342-337e2b4294e5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(100,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#limitation of window based model:"
      ],
      "metadata": {
        "id": "dXPIAjZlLqrt"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fixed window_size\n",
        "#capture limited context\n",
        "#thats why we need memory so we need rnn\n"
      ],
      "metadata": {
        "id": "9rKgg4gsLr93"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "13dw4cvzL-fh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "name": "Welcome To Colab",
      "toc_visible": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}